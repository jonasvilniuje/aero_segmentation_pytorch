# -*- coding: utf-8 -*-
"""Romain - vessel recognition - only train & predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V3Uv-a6bV3Jg8iglH8ueDHAw8El3-dIz

# Pre
"""

# ! pwd

import tensorflow as tf

# Check if TensorFlow is using the GPU
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

from google.colab import drive
drive.mount('/content/drive')

"""# Download and sort images"""

# run once per session
# to shorten the time of downloads it's possible to leave only imgs with ships in the newly created zip.
# it seems that it's unnecessary step since I have all the pictures in the drive already
# 1. STEP ONE - copy kaggle.json to /root/.kaggle/
# 2. STEP TWO - uncomment the following lines (download and extract dataset)
#
! pwd
! kaggle competitions download -c airbus-ship-detection
! unzip -q airbus-ship-detection.zip

# ! unzip -q training_data_1k_256.zip
# # ! unzip -q training_data_10k_256.zip
# ! unzip -q training_data_40k_256.zip
# ! unzip -q testing_data.zip
# ! unzip -q validation_data.zip
# ! unzip drive/MyDrive/Colab_Notebooks/training_data_40k_256.zip -d drive/MyDrive/Colab_Notebooks/
# ! unzip -q Documents/training_data_40k_256.zip

# ! zip -r training_data_1k_256.zip training_data
# ! zip -r testing_data.zip testing_data
# ! zip -r validation_data.zip validation_data

# ! pwd
# # ! ls drive/MyDrive/Colab_Notebooks/training_data/train/mask/ | wc -l
# ! ls Documents/airbus-ship-detection/training_data/train/mask/ | wc -l
# ! ls Documents/airbus-ship-detection/testing_data/mask/ | wc -l
# ! ls Documents/airbus-ship-detection/validation_data/mask/ | wc -l

# # ! pip install numpy
# # ! pip install pandas
# # ! pip install matplotlib
# # ! pip install tensorflow
# ! pip install scikit-image
# ! pip install opencv-python



import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras

from skimage.io import imread, imshow
from skimage.transform import resize

import os

"""# Define variables"""

# create defined-size subsets for training and testing out of the whole dataset (192k imgs)

import shutil
import os
import sys
import time
import cv2
from PIL import Image
import pathlib

# augmentations_enabled = False

images_with_ship_count = 42556

testing_dataset_size = 2000
validation_dataset_size = 2000
training_dataset_size = 16000
training_size = training_dataset_size

TRAIN_PATH = 'train_v2/'
data_dir_raw = pathlib.Path('train_v2');

batch_size = 10

IMG_WIDTH = 768
IMG_HEIGHT = 768

IMG_WIDTH_SET = 256
IMG_HEIGHT_SET = 256

IMG_CHANNELS = 3

counter_ship_train = 0
counter_ship_test = 0
counter_ship_validation = 0
counter = 0

"""# Data Preparation"""

df_csv = pd.read_csv('train_ship_segmentations_v2.csv')
# df_csv = pd.read_csv('drive/MyDrive/Colab Notebooks/train_ship_segmentations_v2.csv')
df_without_nan = df_csv.dropna(how='any')
df_csv_grouped = df_without_nan.groupby('ImageId')['EncodedPixels'].apply(' '.join)

df_csv['has_vessel'] = df_csv['EncodedPixels'].notnull()
mask_has_vessel = df_csv['has_vessel']

# create a dict where image name is the key and ship presence is the value in binary
df_labels = df_csv.groupby('ImageId')['has_vessel'].max()
df_labels = df_labels.astype(str)
df_labels.head(10)

# remove corrupted images.
exclude_list = [
    "6384c3e78.jpg",
    "13703f040.jpg",
    "14715c06d.jpg",
    "33e0ff2d5.jpg",
    "4d4e09f2a.jpg",
    "877691df8.jpg",
    "8b909bb20.jpg",
    "a8d99130e.jpg",
    "ad55c3143.jpg",
    "c8260c541.jpg",
    "d6c7f17c7.jpg",
    "dc3e7c901.jpg",
    "e44dffe88.jpg",
    "ef87bad36.jpg",
    "f083256d8.jpg",
    '134c8ead9.jpg',
    '331bc6b0c.jpg',
    '331ca6f3b.jpg'
]

# ref.: https://www.kaggle.com/stainsby/fast-tested-rle

DEFAULT_IMAGE_SHAPE = (768,768)

def rle2mask(mask_rle: str, label=1, shape=DEFAULT_IMAGE_SHAPE):
    """
    mask_rle: run-length as string formatted (start length)
    shape: (height,width) of array to return
    Returns numpy array, 1 - mask, 0 - background

    """
    s = mask_rle.split()
    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]
    starts -= 1
    ends = starts + lengths
    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)
    for lo, hi in zip(starts, ends):
        img[lo:hi] = label
    # print('mask shape: ', img.reshape(shape).shape)
    # print('mask min: ', img.reshape(shape).min())
    # print('mask max: ', img.reshape(shape).max())
    return np.flip(np.rot90(img.reshape(shape), 3), 1) # Needed to align to RLE direction

def rle_to_pixels(rle_code):
    '''
    Transforms a RLE code string into a list of pixels of a (768, 768) canvas

    Source: https://www.kaggle.com/julian3833/2-understanding-and-plotting-rle-bounding-boxes
    '''
    rle_code = [int(i) for i in rle_code.split()]
    pixels = [(pixel_position % 768, pixel_position // 768)
                 for start, length in list(zip(rle_code[0:-1:2], rle_code[1::2]))
                 for pixel_position in range(start, start + length-1)] # edited
    return pixels


def create_an_empty_mask(
    IMG_WIDTH=768, IMG_HEIGHT=768
):
  return np.zeros((IMG_HEIGHT, IMG_WIDTH))

def create_a_mask(
    df_csv_grouped, img_id, IMG_WIDTH=768, IMG_HEIGHT=768
):
  pixels = rle2mask(df_csv_grouped[img_id])

  return pixels

# --------------- show random image and its mask ---------------
def show_random_image_and_its_mask(
    df_csv, ship=True, input_dir=str(data_dir_raw)
):
    df_without_nan = df_csv.dropna(how='any')
    df_csv_grouped = df_without_nan.groupby('ImageId')['EncodedPixels'].apply(' '.join)
    print(df_csv_grouped)
    random_img_id = np.random.choice(df_csv.loc[mask_has_vessel, 'ImageId'])

    image = plt.imread(input_dir + "/" + random_img_id)
    mask = create_a_mask(df_csv_grouped, random_img_id)

    rows = 1
    columns = 2
    fig = plt.figure(figsize=(10, 5))
    fig.add_subplot(rows, columns, 1)
    plt.imshow(image)
    fig.add_subplot(rows, columns, 2)
    plt.imshow(mask)

df_csv = pd.read_csv('train_ship_segmentations_v2.csv')
# df_csv = pd.read_csv('drive/MyDrive/Colab Notebooks/train_ship_segmentations_v2.csv')
df_without_nan = df_csv.dropna(how='any')
df_csv_grouped = df_without_nan.groupby('ImageId')['EncodedPixels'].apply(' '.join)

df_csv['has_vessel'] = df_csv['EncodedPixels'].notnull()
mask_has_vessel = df_csv['has_vessel']

# create a dict where image name is the key and ship presence is the value in binary
df_labels = df_csv.groupby('ImageId')['has_vessel'].max()
df_labels = df_labels.astype(str)
df_labels.head(10)

# remove corrupted images.
exclude_list = [
    "6384c3e78.jpg",
    "13703f040.jpg",
    "14715c06d.jpg",
    "33e0ff2d5.jpg",
    "4d4e09f2a.jpg",
    "877691df8.jpg",
    "8b909bb20.jpg",
    "a8d99130e.jpg",
    "ad55c3143.jpg",
    "c8260c541.jpg",
    "d6c7f17c7.jpg",
    "dc3e7c901.jpg",
    "e44dffe88.jpg",
    "ef87bad36.jpg",
    "f083256d8.jpg",
    '134c8ead9.jpg',
    '331bc6b0c.jpg',
    '331ca6f3b.jpg'
]

"""# Define functions for creating masks"""

# ref.: https://www.kaggle.com/stainsby/fast-tested-rle

DEFAULT_IMAGE_SHAPE = (768,768)

def rle2mask(mask_rle: str, label=1, shape=DEFAULT_IMAGE_SHAPE):
    """
    mask_rle: run-length as string formatted (start length)
    shape: (height,width) of array to return
    Returns numpy array, 1 - mask, 0 - background

    """
    s = mask_rle.split()
    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]
    starts -= 1
    ends = starts + lengths
    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)
    for lo, hi in zip(starts, ends):
        img[lo:hi] = label
    # print('mask shape: ', img.reshape(shape).shape)
    # print('mask min: ', img.reshape(shape).min())
    # print('mask max: ', img.reshape(shape).max())
    return np.flip(np.rot90(img.reshape(shape), 3), 1) # Needed to align to RLE direction

def rle_to_pixels(rle_code):
    '''
    Transforms a RLE code string into a list of pixels of a (768, 768) canvas

    Source: https://www.kaggle.com/julian3833/2-understanding-and-plotting-rle-bounding-boxes
    '''
    rle_code = [int(i) for i in rle_code.split()]
    pixels = [(pixel_position % 768, pixel_position // 768)
                 for start, length in list(zip(rle_code[0:-1:2], rle_code[1::2]))
                 for pixel_position in range(start, start + length-1)] # edited
    return pixels


def create_an_empty_mask(
    IMG_WIDTH=768, IMG_HEIGHT=768
):
  return np.zeros((IMG_HEIGHT, IMG_WIDTH))

def create_a_mask(
    df_csv_grouped, img_id, IMG_WIDTH=768, IMG_HEIGHT=768
):
  pixels = rle2mask(df_csv_grouped[img_id])

  return pixels

# --------------- show random image and its mask ---------------
def show_random_image_and_its_mask(
    df_csv, ship=True, input_dir=str(data_dir_raw)
):
    df_without_nan = df_csv.dropna(how='any')
    df_csv_grouped = df_without_nan.groupby('ImageId')['EncodedPixels'].apply(' '.join)
    print(df_csv_grouped)
    random_img_id = np.random.choice(df_csv.loc[mask_has_vessel, 'ImageId'])

    image = plt.imread(input_dir + "/" + random_img_id)
    mask = create_a_mask(df_csv_grouped, random_img_id)

    rows = 1
    columns = 2
    fig = plt.figure(figsize=(10, 5))
    fig.add_subplot(rows, columns, 1)
    plt.imshow(image)
    fig.add_subplot(rows, columns, 2)
    plt.imshow(mask)

"""# Images: prepare masks"""

# goal - run once, save all masks and img to folder and upload it to drive
# run once per session

# ! rm -rf training_data

!mkdir training_data
!mkdir training_data/train

!mkdir training_data/train/img/
!mkdir training_data/train/mask/
counter_ship_train = 0

for item in sorted(data_dir_raw.glob('*.jpg')):
  if counter_ship_train > training_dataset_size: break

  item_str = str(item)
  item_basename_str = os.path.basename(item_str)

  if item_basename_str not in exclude_list:

    if df_labels[item_basename_str] == 'True':
      item_save_str = 'training_data/train/img/' + item_basename_str
      mask_save_str = 'training_data/train/mask/' + item.stem + '.png'

      mask = create_a_mask(df_csv_grouped, item_basename_str, IMG_WIDTH, IMG_HEIGHT)

      plt.imsave(mask_save_str, np.squeeze(mask), cmap='gray') # corresponding mask
      cv2.imwrite(mask_save_str, cv2.resize(cv2.imread(mask_save_str), (IMG_WIDTH_SET, IMG_HEIGHT_SET)))
      cv2.imwrite(item_save_str, cv2.resize(cv2.imread(str(data_dir_raw) + '/' + item_basename_str), (IMG_WIDTH_SET, IMG_HEIGHT_SET)))

      counter_ship_train += 1

    # implementation to use imgs without ships
    # else:
    #   item_save_str = 'training_data/train/img/' + item_basename_str
    #   mask_save_str = 'training_data/train/mask/' + item.stem + '.png'

    #   mask = create_an_empty_mask()
    #   # mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True), axis=-1)

    #   plt.imsave(mask_save_str, np.squeeze(mask), cmap='gray') # corresponding mask
    #   shutil.copy(str(data_dir_raw) + '/' + item_basename_str, item_save_str)

    #   counter_ship_train += 1
  else:
    print('excluded: ', item_basename_str)

print('finished, collected ' + str(counter_ship_train) + ' imgs and masks'), item_str

# save images for TESTING + VALIDATION purpose ONLY and use always the same ones for accurate measurments
# this is why we're picking imgs from the other end

# ! rm -rf testing_data
# ! rm -rf validation_data

!mkdir testing_data
!mkdir testing_data/img/
!mkdir testing_data/mask/

!mkdir validation_data
!mkdir validation_data/img/
!mkdir validation_data/mask/

counter_ship_test = 0

for item in reversed(sorted(data_dir_raw.glob('*.jpg'))):
  if counter_ship_test > validation_dataset_size + testing_dataset_size: break

  item_str = str(item)
  item_basename_str = os.path.basename(item_str)

  if item_basename_str not in exclude_list:
    if df_labels[item_basename_str] == 'True':

      if counter_ship_test < testing_dataset_size:
        item_save_str = 'testing_data/img/' + item_basename_str
        mask_save_str = 'testing_data/mask/' + item.stem + '.png'
      else:
        item_save_str = 'validation_data/img/' + item_basename_str
        mask_save_str = 'validation_data/mask/' + item.stem + '.png'

      mask = create_a_mask(df_csv_grouped, item_basename_str, IMG_WIDTH, IMG_HEIGHT)
      plt.imsave(mask_save_str, np.squeeze(mask), cmap='gray') # corresponding mask
      cv2.imwrite(mask_save_str, cv2.resize(cv2.imread(mask_save_str), (IMG_WIDTH_SET, IMG_HEIGHT_SET)))
      cv2.imwrite(item_save_str, cv2.resize(cv2.imread(str(data_dir_raw) + '/' + item_basename_str), (IMG_WIDTH_SET, IMG_HEIGHT_SET)))

      counter_ship_test += 1
  else:
    print('excluded: ', item_basename_str)

print('finished, collected ' + str(counter_ship_test) + ' imgs and masks'), item_str

"""read image metadata
and generate new columns

define most of the parameters

END OF DOWNLOADING, SORTING IMAGES AND CREATING MASKS

# Begin initializing model
"""

import cv2
from skimage.io import imread
from skimage.transform import resize
from tensorflow.keras.utils import Sequence
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
import math
import random

# Here, `x_set` is list of path to the images
# and `y_set` are the associated classes.

IMG_WIDTH = 256
IMG_HEIGHT = 256
print(IMG_WIDTH, 'x', IMG_HEIGHT)

class vessels_dataset(Sequence):
    def __init__(self, x_set, y_set, batch_size):
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size
        self.augmentations = augmentations
        self.seed = seed

    def __len__(self):
        return math.ceil(len(self.x) / self.batch_size)

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) *
        self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) *
        self.batch_size]

        return cv2.normalize(np.array([cv2.imread(file_name) for file_name in batch_x]), None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F), np.expand_dims(np.abs(np.array([cv2.imread(file_name, cv2.IMREAD_GRAYSCALE) for file_name in batch_y], dtype=np.int8)), axis=-1)


class vessels_dataset_train(Sequence):
    def __init__(self, x_set, y_set, batch_size, augmentations=None, seed=0):
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size
        self.augmentations = augmentations
        self.seed = seed

    def __len__(self):
        return math.ceil(len(self.x) / self.batch_size)

    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) *
        self.batch_size]
        batch_y = self.y[idx * self.batch_size:(idx + 1) *
        self.batch_size]

        batch_x, batch_y = cv2.normalize(np.array([cv2.imread(file_name) for file_name in batch_x]), None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F), np.expand_dims(np.abs(np.array([cv2.imread(file_name, cv2.IMREAD_GRAYSCALE) for file_name in batch_y], dtype=np.int8)), axis=-1)

        # if augmentations is None:
        return batch_x, batch_y
        # else:
        #   # Prepare the data augmentation generator

        #   gen = ImageDataGenerator(**self.augmentations)

        #   # Apply the augmentations
        #   batch_x_augmented = np.array([
        #       gen.random_transform(x, seed=self.seed) for x in batch_x
        #   ])

        #   batch_y_augmented = np.array([
        #       gen.random_transform(y, seed=self.seed) for y in batch_y
        #   ])

        #   return batch_x_augmented, batch_y_augmented

! ls drive/MyDrive/Colab_Notebooks/training_data/train/img | wc -l
! ls drive/MyDrive/Colab_Notebooks/training_data/train/mask | wc -l

# # base_path = 'drive/MyDrive/Colab_Notebooks/'
# # base_path = 'Documents/airbus-ship-detection/'

# filenames = [item for item in sorted(os.listdir(f'{base_path}training_data/train/img/'))]
# filenames_test = [item for item in sorted(os.listdir(f'{base_path}testing_data/img/'))]
# filenames_validate = [item for item in sorted(os.listdir(f'{base_path}validation_data/img/'))]

# filenames_dataset_train = filenames[0 : training_dataset_size]
# filenames_dataset_test = filenames_test[0 : testing_dataset_size]
# filenames_dataset_validate = filenames_validate[0 : validation_dataset_size]

# files_img = [f'{base_path}training_data/train/img/' + item for item in filenames_dataset_train]
# files_mask = [f'{base_path}training_data/train/mask/' + item.split('.')[0]+'.png' for item in filenames_dataset_train]

# files_img_test =  [f'{base_path}testing_data/img/' + item for item in filenames_dataset_test]
# files_mask_test = [f'{base_path}testing_data/mask/' + item.split('.')[0]+'.png' for item in filenames_dataset_test]

# files_img_valid =  [f'{base_path}validation_data/img/' + item for item in filenames_dataset_validate]
# files_mask_valid = [f'{base_path}validation_data/mask/' + item.split('.')[0]+'.png' for item in filenames_dataset_validate]

# print(len(filenames_dataset_train))
# print(len(filenames_dataset_test))
# print(len(filenames_dataset_validate))

filenames = [item for item in sorted(os.listdir('training_data/train/img/'))]
filenames_test = [item for item in sorted(os.listdir('testing_data/img/'))]
filenames_validate = [item for item in sorted(os.listdir('validation_data/img/'))]

filenames_dataset_train = filenames[0 : training_dataset_size]
filenames_dataset_test = filenames_test[0 : testing_dataset_size]
filenames_dataset_validate = filenames_validate[0 : validation_dataset_size]

# filenames_dataset_validation = [0 : testing_dataset_size]
# filenames_dataset_test = filenames[training_dataset_size+1 : training_dataset_size+1+testing_dataset_size]
# filenames_dataset_valid = filename[training_dataset_size+testing_dataset_size+1 : training_dataset_size+testing_dataset_size+validation_dataset_size+1]

files_img = ['training_data/train/img/' + item for item in filenames_dataset_train]
files_mask = ['training_data/train/mask/' + item.split('.')[0]+'.png' for item in filenames_dataset_train]

files_img_test =  ['testing_data/img/' + item for item in filenames_dataset_test]
files_mask_test = ['testing_data/mask/' + item.split('.')[0]+'.png' for item in filenames_dataset_test]

files_img_valid =  ['validation_data/img/' + item for item in filenames_dataset_validate]
files_mask_valid = ['validation_data/mask/' + item.split('.')[0]+'.png' for item in filenames_dataset_validate]

print(len(filenames_dataset_train))
print(len(filenames_dataset_test))
print(len(filenames_dataset_validate))

augmentations_enabled = False

if augmentations_enabled:
  augmentations = {
      "rotation_range": 180,
      "width_shift_range": 0.1,
      "height_shift_range": 0.1,
      "shear_range": 0.1,
      "zoom_range": 0.1,
      "horizontal_flip": True,
      "fill_mode": 'nearest'
  }
else:
  augmentations = None

is_augmentations_enabled_title = ''
if augmentations_enabled:
  is_augmentations_enabled_title = 'augmentations enabled'
else:
  is_augmentations_enabled_title = 'augmentations disabled'

import random

seed = random.randrange(0, 101, 2)

# sequence_dataset = vessels_dataset(files_img, files_mask, batch_size, augmentations)
# sequence_dataset_test = vessels_dataset(files_img_test, files_mask_test, batch_size, augmentations)
# sequence_dataset_valid = vessels_dataset(files_img_valid, files_mask_valid, batch_size, augmentations)

# sequence_dataset = vessels_dataset(files_img, files_mask, batch_size)
sequence_dataset = vessels_dataset_train(files_img, files_mask, batch_size, augmentations, seed)
sequence_dataset_test = vessels_dataset(files_img_test, files_mask_test, batch_size)
sequence_dataset_valid = vessels_dataset(files_img_valid, files_mask_valid, batch_size)

# plot_pred_mask_callback = PerformancePlotCallback(files_img_test, files_mask_test)

f, axarr = plt.subplots(1,2)
f.set_figheight(5)
f.set_figwidth(6)

img_no = 3
batch_no = 0

print(sequence_dataset[batch_no][0].shape)

print(sequence_dataset[batch_no][0][0].shape)
print(sequence_dataset[batch_no][1][0].shape)

print(sequence_dataset[batch_no][0][img_no].min())
print(sequence_dataset[batch_no][0][img_no].max())

print(sequence_dataset[batch_no][1][img_no].min())
print(sequence_dataset[batch_no][1][img_no].max())

axarr[0].imshow(sequence_dataset[batch_no][0][img_no])
axarr[1].imshow(sequence_dataset[batch_no][1][img_no])

f, axarr = plt.subplots(1,2)
f.set_figheight(5)
f.set_figwidth(6)

img_no = 3
batch_no = 0

print(sequence_dataset_valid[batch_no][0].shape)

print(sequence_dataset_valid[batch_no][0][0].shape)
print(sequence_dataset_valid[batch_no][1][0].shape)

print(sequence_dataset_valid[batch_no][0][img_no].min())
print(sequence_dataset_valid[batch_no][0][img_no].max())

print(sequence_dataset_valid[batch_no][1][img_no].min())
print(sequence_dataset_valid[batch_no][1][img_no].max())

axarr[0].imshow(sequence_dataset_valid[batch_no][0][img_no])
axarr[1].imshow(sequence_dataset_valid[batch_no][1][img_no])

class PerformancePlotCallback(keras.callbacks.Callback):
    def __init__(self):
        self.loss = []
        self.binary_io_u = []
        self.val_loss = []
        self.val_binary_io_u = []
        self.logs = []

    def on_epoch_end(self, epoch, logs=None):
        # current = logs.get("loss")
        # Append the logs, losses and accuracies to the lists
        self.logs.append(logs)
        self.loss.append(logs.get('loss'))
        self.binary_io_u.append(logs.get('binary_io_u'))
        self.val_loss.append(logs.get('val_loss'))
        self.val_binary_io_u.append(logs.get('val_binary_io_u'))

        # Before plotting ensure at least 2 epochs have passed
        if len(self.loss) > 1:

            N = np.arange(0, len(self.loss))
            keys = list(logs.keys())
            # print(" End epoch {} of training; got log keys: {}".format(epoch, keys))
            plt.figure()
            plt.plot(self.loss)
            plt.plot(self.val_loss)
            plt.plot(self.binary_io_u)
            plt.plot(self.val_binary_io_u)

            plt.title(f'model loss/mean_iou per epoch, {training_dataset_size} imgs, {epoch+1} epochs')
            plt.ylabel('loss/mean_iou')
            plt.xlabel('epoch')
            plt.legend(['loss', 'val_loss', 'mean_io_u', 'validation_mean_io_u'])
            plt.grid()
            plt.show()

    # def on_epoch_end(self, epoch, logs=None):
    #     print('Evaluating Model...')
    #     print('Model Evaluation: ', self.model.evaluate(self.x_test))

"""# Loss functions

"""

import keras.backend as K

def dice_loss(y_true, y_pred):
    smooth = 1.
    y_true_f = K.flatten(K.cast(y_true, 'float32'))  # cast y_true to float32
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)

def DiceBCELoss(targets, inputs, smooth=1e-6):

    #flatten label and prediction tensors
    inputs = K.flatten(inputs)
    targets = K.flatten(K.cast(targets, 'float32'))

    BCE =  tf.keras.losses.binary_crossentropy(targets, inputs)
    intersection = K.sum(K.dot(targets, inputs))
    dice_loss = 1 - (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)
    Dice_BCE = BCE + dice_loss

    return Dice_BCE

#Keras
def IoULoss(targets, inputs, smooth=1e-6):
    #flatten label and prediction tensors
    inputs = K.flatten(inputs)
    targets = K.flatten(K.cast(targets, 'float32'))

    intersection = K.sum(K.dot(targets, inputs))
    total = K.sum(targets) + K.sum(inputs)
    union = total - intersection

    IoU = (intersection + smooth) / (union + smooth)
    return 1 - IoU

#Keras
ALPHA = 0.8
GAMMA = 2

def FocalLoss(targets, inputs, alpha=ALPHA, gamma=GAMMA):

    inputs = K.flatten(inputs)
    targets = K.flatten(K.cast(targets, 'float32'))

    BCE = K.binary_crossentropy(targets, inputs)
    BCE_EXP = K.exp(-BCE)
    focal_loss = K.mean(alpha * K.pow((1-BCE_EXP), gamma) * BCE)

    return focal_loss

#Keras
ALPHA = 0.5
BETA = 0.5

def TverskyLoss(targets, inputs, alpha=ALPHA, beta=BETA, smooth=1e-6):

        #flatten label and prediction tensors
        inputs = K.flatten(inputs)
        targets = K.flatten(K.cast(targets, 'float32'))

        #True Positives, False Positives & False Negatives
        TP = K.sum((inputs * targets))
        FP = K.sum(((1-targets) * inputs))
        FN = K.sum((targets * (1-inputs)))

        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)

        return 1 - Tversky

#Keras
ALPHA = 0.5
BETA = 0.5
GAMMA = 1

def FocalTverskyLoss(targets, inputs, alpha=ALPHA, beta=BETA, gamma=GAMMA, smooth=1e-6):

        #flatten label and prediction tensors
        inputs = K.flatten(inputs)
        targets = K.flatten(K.cast(targets, 'float32'))

        #True Positives, False Positives & False Negatives
        TP = K.sum((inputs * targets))
        FP = K.sum(((1-targets) * inputs))
        FN = K.sum((targets * (1-inputs)))

        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)
        FocalTversky = K.pow((1 - Tversky), gamma)

        return FocalTversky



def dice_coef(y_true, y_pred, smooth=1e-16):
    y_true_f = tf.nest.flatten(y_true)
    y_pred_f = tf.nest.flatten(y_pred)

    y_true_f = tf.cast(y_true_f, tf.float32)
    y_pred_f = tf.cast(y_pred_f, tf.float32)

    intersection = tf.math.reduce_sum(tf.math.multiply(y_true_f, y_pred_f))
    return (2. * intersection + smooth) / (tf.math.reduce_sum(y_true_f) + tf.math.reduce_sum(y_pred_f) + smooth)



"""# load model?


"""

# model = tf.keras.models.load_model(
#     '/content/drive/MyDrive/Colab_Notebooks/saved_model_10_epochs_10k_imgs_fixed_masks/'
# )
# model = tf.keras.models.load_model(
#     '/content/drive/MyDrive/Colab_Notebooks/saved_model_BinaryCrossentropy_25_epochs_10000_imgs_is_augmented_False/'
# )

"""# define model architecture"""

tf.keras.backend.clear_session()

# ! pip install jupyter_http_over_ws
# ! jupyter serverextension enable --py jupyter_http_over_ws

import tensorflow as tf
import os
import time

start = time.time()

tf.keras.backend.clear_session()

# expects (IMG_WIDTH, IMG_HEIGHT, 1)

# IMG_WIDTH = 256
# IMG_HEIGHT = 256
# IMG_CHANNELS = 3


loss_function = 'BinaryCrossentropy'
# loss_function = 'FocalLoss'
# loss_function = 'DiceLoss'

#Build the model
inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, 3))
s = inputs

#Contraction path
c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)
c1 = tf.keras.layers.Dropout(0.1)(c1)
# c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)
p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)

c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)
c2 = tf.keras.layers.Dropout(0.1)(c2)
# c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)
p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)

c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)
c3 = tf.keras.layers.Dropout(0.2)(c3)
# c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)
p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)

c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)
c4 = tf.keras.layers.Dropout(0.2)(c4)
# c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)
p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)

c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)
c5 = tf.keras.layers.Dropout(0.3)(c5)
c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)

#Expansive path
u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
u6 = tf.keras.layers.concatenate([u6, c4])
c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)
c6 = tf.keras.layers.Dropout(0.2)(c6)
# c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)

u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
u7 = tf.keras.layers.concatenate([u7, c3])
c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)
c7 = tf.keras.layers.Dropout(0.2)(c7)
# c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)

u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
u8 = tf.keras.layers.concatenate([u8, c2])
c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)
c8 = tf.keras.layers.Dropout(0.1)(c8)
# c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)

u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
u9 = tf.keras.layers.concatenate([u9, c1], axis=3)
c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)
c9 = tf.keras.layers.Dropout(0.1)(c9)
# c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)

outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)

model = tf.keras.Model(inputs=[inputs], outputs=[outputs])

"""# Train"""

print('augmentations_enabled? ', augmentations_enabled)
# print(augmentations_enabled_title)

tf.keras.backend.clear_session() # clear or continue training from checkpoint?

epochs = 25
# optimizer = keras.optimizers.Adam(learning_rate=0.001)

loss_function = 'BinaryCrossentropy'
# loss_function = 'FocalLoss'
# loss_function = 'DiceLoss'

# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=tf.keras.metrics.MeanIoU(num_classes=2))
# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=tf.keras.metrics.MeanIoU(num_classes=2, ignore_class=0))
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.BinaryIoU(target_class_ids=[1], threshold=0.5)])
# model.compile(optimizer='adam', loss=DiceLoss, metrics=[tf.keras.metrics.BinaryIoU(target_class_ids=[1], threshold=0.5)]) # regis per 50 epochų nieko neišmoko
# model.compile(optimizer='adam', loss=IoULoss, metrics=[tf.keras.metrics.BinaryIoU(target_class_ids=[1], threshold=0.5)]) # neveikia
# model.compile(optimizer='adam', loss=DiceBCELoss, metrics=[tf.keras.metrics.BinaryIoU(target_class_ids=[1], threshold=0.5)])
# model.compile(optimizer='adam', loss=FocalLoss, metrics=[tf.keras.metrics.BinaryIoU(target_class_ids=[1], threshold=0.5)])
# model.compile(optimizer='adam', loss=TverskyLoss, metrics=[tf.keras.metrics.BinaryIoU(target_class_ids=[1], threshold=0.5)])
# model.compile(optimizer='adam', loss=TverskyDiceLoss, metrics=[tf.keras.metrics.BinaryIoU(target_class_ids=[1], threshold=0.5)])

earlystopper = tf.keras.callbacks.EarlyStopping(monitor='val_binary_io_u', mode='max', verbose=1, patience=10)
# checkpoint = tf.keras.callbacks.ModelCheckpoint(f'saved_checkpoint_{training_dataset_size}_{epochs}_{loss_function}_{is_augmentations_enabled_title}', monitor='val_binary_io_u', verbose=1,
#                              save_best_only=True, mode='min')

import time

start = time.time()

results = model.fit(
    sequence_dataset,
    epochs=epochs,
    steps_per_epoch=training_dataset_size // batch_size,
    validation_data=sequence_dataset_valid,
    validation_steps=validation_dataset_size  // batch_size,
    callbacks=[PerformancePlotCallback()]
    # callbacks=[earlystopper, PerformancePlotCallback(), checkpoint]
)

end = time.time()

print(end - start)

# losss funkcijos grafikas per epochas +
# daugiau duomenu +
# test data ta pacia imt reiks, validavimo dataset irgi +
# reikia validuoti tarpinius mokymosi rezultatus +

# reikia daugiau eksperimentu - kažkokią reikia metodiką sugalvoti,
  # kad patikrinti kiek hiperparamterai, duomenų kiekis ir tinklo gylis turi įtakos tikslumui ir laikui
# metodika:
# 1 paimti baseline modelį, apmokyti jį su skirtingais duomenų kiekiais
# 2 tobulinti baseline modelį -
  # pridėti augmentaciją, keisti learning rate, loss funkcijas (BCE vs Dice vs Focal) keisti modelio gylį (gal)
# palyginti mean_iou, kreives mokymosi, vizualius segmentavimo rezultatus, sunaudotą laiką


# 100/100 [==============================] - 17s 166ms/step - loss: 9.9502e-04 - binary_io_u: 0.7056 - val_loss: 0.0025 - val_binary_io_u: 0.5255
# 1872.2088241577148 (31m), BCE, 1000, 50 slow bc data reading is from drive!

# 1000/1000 [==============================] - 33s 33ms/step - loss: 0.0047 - binary_io_u: 0.6994 - val_loss: 0.0051 - val_binary_io_u: 0.6788
# 862.214453458786, BCE, 10000, 25

# 1000/1000 [==============================] - 33s 33ms/step - loss: 0.0048 - binary_io_u: 0.7005 - val_loss: 0.0051 - val_binary_io_u: 0.6792
# 881.161518573761, BCE, 10000, 25, not augmented, testing results: loss 0.005156033206731081, mean_iou 0.6909050941467285

# 1000/1000 [==============================] - 33s 33ms/step - loss: 0.0048 - binary_io_u: 0.6986 - val_loss: 0.0051 - val_binary_io_u: 0.6848
# 835.1496427059174, BCE, 10000, 25, augmented, testing results: loss 0.005128573626279831, mean_iou 0.6884132027626038

# 2000/2000 [==============================] - 63s 32ms/step - loss: 0.0042 - binary_io_u: 0.7316 - val_loss: 0.0039 - val_binary_io_u: 0.7342
# 1654.9180595874786, BCE, 20000, 25, augmented, testing results: loss: 0.0041 - binary_io_u: 0.7351

# 2000/2000 [==============================] - 62s 31ms/step - loss: 0.0036 - binary_io_u_1: 0.7603 - val_loss: 0.0036 - val_binary_io_u_1: 0.7516
# 1700.15105843544, BCE, 20000, 50, augmented, testing results: loss 0.003516847500577569, mean_iou 0.7604515552520752

# loss: 0.0041 - binary_io_u: 0.7316 - val_loss: 0.0037 - val_binary_io_u: 0.7398
# 3114.3021972179413, BCE, 40000, 25, augmented, testing results: loss 0.0037593087181448936, mean_iou 0.7485917806625366

save_dir = f'drive/MyDrive/Colab_Notebooks/results_{loss_function}_{training_dataset_size}_imgs_{epochs}_epochs/'

try:
    os.mkdir(save_dir)
except OSError as error:
    print(error)

save_img_str = f'{save_dir}loss_graph_is_augmented_{augmentations_enabled}.png'

print(results.history.keys())

plt.plot(results.history['loss'])
plt.plot(results.history['val_loss'])
plt.title(f'{loss_function}, {training_dataset_size} imgs, {epochs} epochs, {is_augmentations_enabled_title}')

plt.xlabel('epoch')
plt.ylabel('loss function value')
plt.legend(['training loss', 'validation loss'], loc='upper left')

plt.grid()
plt.savefig(save_img_str)

try:
    os.mkdir(save_dir)
except OSError as error:
    print(error)

save_img_str = f'{save_dir}mean_iou_graph_is_augmented_{augmentations_enabled}.png'

print(results.history.keys())

plt.plot(results.history['binary_io_u'])
plt.plot(results.history['val_binary_io_u'])
plt.title(f'Focal loss, {training_dataset_size} imgs, {epochs} epochs, {is_augmentations_enabled_title}')

plt.xlabel('epoch')
plt.ylabel('mean_iou')
plt.legend(['mean_io_u', 'validation_mean_io_u'], loc='upper left')

plt.grid()
plt.savefig(save_img_str)

# plt.annotate('local max', xy=(xmax, ymax), xytext=(xmax, ymax+5),
#             arrowprops=dict(facecolor='black', shrink=0.05),
#             )

model_save_dir = f'drive/MyDrive/Colab_Notebooks/saved_model_{loss_function}_{epochs}_epochs_{training_dataset_size}_imgs_is_augmented_{augmentations_enabled}/'
try:
    os.mkdir(model_save_dir)
except OSError as error:
    print(error)

model.save(f'{model_save_dir}')

print(max(results.history['binary_io_u']))
print(max(results.history['val_binary_io_u']))

res = model.predict(sequence_dataset_test)

print(res.shape)
print(res[0].shape)
print(res[0].min())
print(res[0].max())
# print(res.argmax())

"""**The most important metrics!**"""

testing_res = model.evaluate(sequence_dataset_test, steps=testing_dataset_size // batch_size)

print(f'testing results: loss {testing_res[0]}, mean_iou {testing_res[1]}', )

from re import I
num = 10
no_of_batches = 10
f, axarr = plt.subplots(num,3)
# f, axarr = plt.subplots(num*no_of_batches,3)
f.set_figheight(3*num)
f.set_figwidth(10)

# difficult imgs [7][1], [4][0], [4][3] [5][5] [5][9]

# img_no = 9
batch_no = 4

u = 0

print(sequence_dataset_test[0][0][0].shape)

# for batch_no in range(0, 3):
for i in range(0, num):
  img_no = i
  axarr[u, 0].imshow(sequence_dataset_test[batch_no][0][img_no])

  axarr[u, 1].imshow(sequence_dataset_test[batch_no][1][img_no])

  axarr[u, 2].imshow(np.squeeze(res[batch_no*10+img_no]))
  u = u + 1

save_img_str = f'{save_dir}segmentation_results_is_augmented_{augmentations_enabled}.png'
plt.savefig(save_img_str)

# # plt.imsave('res[0].png', np.squeeze(res[0]))

# print(res.shape[0])

# for i in range(0, res.shape[0]):
#   save_img_str = f'drive/MyDrive/Colab_Notebooks/result_10000_imgs/res[{i}].png'
#   plt.imsave(save_img_str, np.squeeze(res[i]))

# b = 0
# for i in range(0, res.shape[0]):
#   for ii in range(0, 9):
#     axarr[0].imshow(sequence_dataset_test[b][0][ii])
#     axarr[1].imshow(sequence_dataset_test[b][1][ii])
#     axarr[2].imshow(np.squeeze(res[i]))
#  plt.title(f'model loss/mean_iou per epoch, {training_dataset_size} imgs, {epoch+1} epochs')
#     save_img_str = f'drive/MyDrive/Colab_Notebooks/result_10000_imgs/compare_truth_mask_result/compare{i}.png'
#     plt.imsave(save_img_str, np.squeeze(res[i]))
#     i = i + 1
#   b = b + 1

"""saving a model"""

# ! zip -r saved_model_10_epochs_40k.zip /content/drive/MyDrive/Colab_Notebooks/saved_model_10_epochs_40k/